{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f02a0c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/08/18 17:19:18 WARN Utils: Your hostname, LAPTOP-E04ANIN1, resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "25/08/18 17:19:18 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/18 17:19:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Starts a Spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"Taxi vs Rideshare Profitability\")\n",
    "        .config(\"spark.sql.repl.eagerEval.enabled\", False)   \n",
    "        .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "        .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"320\")\n",
    "        .config(\"spark.sql.adaptive.enabled\", \"true\") \n",
    "        .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\")       \n",
    "        .config(\"spark.driver.memory\", \"6g\")                \n",
    "        .config(\"spark.executor.memory\", \"6g\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "# Define months\n",
    "months = [\"2024-01\",\"2024-02\",\"2024-03\",\"2024-04\",\"2024-05\",\"2024-06\"]\n",
    "\n",
    "# Load in data files \n",
    "yellow_files = [f\"data/yellow/yellow_tripdata_{m}.parquet\" for m in months]\n",
    "fhvhv_files  = [f\"data/fhvhv/fhvhv_tripdata_{m}.parquet\"   for m in months]\n",
    "\n",
    "df_yellow = (\n",
    "    spark.read.parquet(*yellow_files)\n",
    "         .withColumn(\"service_type\", lit(\"yellow\"))\n",
    ")\n",
    "df_fhvhv = (\n",
    "    spark.read.parquet(*fhvhv_files)\n",
    "         .withColumn(\"service_type\", lit(\"hv_fhv\"))\n",
    ")\n",
    "\n",
    "# Merge\n",
    "df = df_yellow.unionByName(df_fhvhv, allowMissingColumns=True)\n",
    "\n",
    "# External tables \n",
    "electricity = spark.read.csv(\"data/external/electricity.csv\", header=True, inferSchema=True)\n",
    "fuel = spark.read.csv(\"data/external/fuel.csv\", header=True, inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c04cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess data\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, to_timestamp, coalesce, unix_timestamp, when, lit, date_format, hour, dayofweek, broadcast\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql import Window\n",
    "\n",
    "# Reduce memory usage\n",
    "_needed = [\n",
    "    \"service_type\",\n",
    "    \"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\n",
    "    \"pickup_datetime\",\"dropoff_datetime\",\n",
    "    \"trip_distance\",\"trip_miles\",\"trip_time\",\n",
    "    \"PULocationID\",\"DOLocationID\",\n",
    "    \"passenger_count\",\"payment_type\",\n",
    "    \"fare_amount\",\"extra\",\"tip_amount\",\n",
    "    \"driver_pay\",\"tips\"\n",
    "]\n",
    "df = df.select([c for c in _needed if c in df.columns])\n",
    "\n",
    "# Standardise timestamps\n",
    "df = (\n",
    "    df.withColumn(\"pickup_ts\",  to_timestamp(coalesce(col(\"tpep_pickup_datetime\"),  col(\"pickup_datetime\"))))\n",
    "      .withColumn(\"dropoff_ts\", to_timestamp(coalesce(col(\"tpep_dropoff_datetime\"), col(\"dropoff_datetime\"))))\n",
    ")\n",
    "\n",
    "# Remove rows with null pickup or dropoff timestamps\n",
    "df = df.filter(col(\"pickup_ts\").isNotNull() & col(\"dropoff_ts\").isNotNull())\n",
    "\n",
    "# Standardise location IDs\n",
    "df = df.withColumn(\"month\", date_format(col(\"pickup_ts\"), \"yyyy-MM\"))\n",
    "\n",
    "# Standardise distance and keep positive distances only and not null\n",
    "df = (\n",
    "    df.withColumn(\"distance_mi\", coalesce(col(\"trip_distance\"), col(\"trip_miles\")).cast(DoubleType()))\n",
    "      .filter(col(\"distance_mi\").isNotNull() & (col(\"distance_mi\") > 0))\n",
    ")\n",
    "\n",
    "# Standardise trip time and not null\n",
    "df = df.withColumn(\n",
    "    \"trip_time_s\",\n",
    "    when(col(\"trip_time\").isNotNull(), col(\"trip_time\").cast(\"double\"))\n",
    "    .otherwise((unix_timestamp(col(\"dropoff_ts\")) - unix_timestamp(col(\"pickup_ts\"))).cast(\"double\"))\n",
    ")\n",
    "df = df.filter(col(\"trip_time_s\").isNotNull() & (col(\"trip_time_s\") > 0))\n",
    "\n",
    "# Deduplicate rows \n",
    "dedupe_key = [c for c in [\"service_type\",\"pickup_ts\",\"dropoff_ts\",\"PULocationID\",\"DOLocationID\",\"distance_mi\",\"trip_time_s\"] if c in df.columns]\n",
    "\n",
    "# If dedupe_key is empty, we won't deduplicate\n",
    "if dedupe_key:\n",
    "    w = Window.partitionBy([\"month\"] + dedupe_key).orderBy(F.lit(1))\n",
    "    df = df.withColumn(\"__rn\", F.row_number().over(w)).filter(col(\"__rn\") == 1).drop(\"__rn\")\n",
    "\n",
    "# Fixed Parameters\n",
    "CREDIT_CARD_FEE = 0.025 \n",
    "MAINTENANCE_COST_PER_MILE = 0.15\n",
    "MAINTENANCE_COST_PER_MILE_HV = 0.15\n",
    "\n",
    "# Payment type exists\n",
    "if \"payment_type\" not in df.columns:\n",
    "    df = df.withColumn(\"payment_type\", lit(None).cast(IntegerType()))\n",
    "\n",
    "# Time features \n",
    "df = (df\n",
    "    .withColumn(\"pickup_hour\", hour(col(\"pickup_ts\")))\n",
    "    .withColumn(\"pickup_dow\", dayofweek(col(\"pickup_ts\")))  \n",
    "    .withColumn(\"is_weekend\", (col(\"pickup_dow\").isin([1,7])).cast(\"boolean\"))\n",
    ")\n",
    "\n",
    "# Add revenue \n",
    "rev_yellow = coalesce(col(\"fare_amount\"), lit(0.0)) + coalesce(col(\"extra\"), lit(0.0)) + coalesce(col(\"tip_amount\"), lit(0.0))\n",
    "rev_hv     = coalesce(col(\"driver_pay\"), lit(0.0)) + coalesce(col(\"tips\"), lit(0.0))\n",
    "df = df.withColumn(\n",
    "    \"revenue\",\n",
    "    when(col(\"service_type\") == \"yellow\", rev_yellow).otherwise(rev_hv).cast(DoubleType())\n",
    ")\n",
    "\n",
    "# Add costs\n",
    "maint_rate = when(col(\"service_type\") == \"yellow\",\n",
    "                  lit(MAINTENANCE_COST_PER_MILE)\n",
    "              ).otherwise(\n",
    "                  lit(MAINTENANCE_COST_PER_MILE_HV)\n",
    "              )\n",
    "df = df.withColumn(\"expense_maintenance\", (col(\"distance_mi\") * maint_rate).cast(DoubleType()))\n",
    "\n",
    "# Credit card fee \n",
    "df = df.withColumn(\n",
    "     \"expense_cc_processing\",\n",
    "    when((col(\"service_type\") == \"yellow\") & (col(\"payment_type\") == 1),\n",
    "         (lit(CREDIT_CARD_FEE) * col(\"revenue\")).cast(DoubleType()))\n",
    "    .otherwise(lit(0.0))\n",
    ")\n",
    "\n",
    "# Expenses pre-fuel \n",
    "df = df.withColumn(\n",
    "    \"expenses_nonfuel\",\n",
    "    (col(\"expense_maintenance\") + col(\"expense_cc_processing\")).cast(DoubleType())\n",
    ")\n",
    "\n",
    "# Keep distance\n",
    "df = df.filter(col(\"distance_mi\") >= 0.1)\n",
    "\n",
    "# Make sure within month range\n",
    "df = df.filter( (col(\"month\") >= \"2024-01\") & (col(\"month\") <= \"2024-06\") )\n",
    "\n",
    "# Keep duration >= 60 seconds\n",
    "df = df.filter(col(\"trip_time_s\") >= 60)\n",
    "\n",
    "# Keep positive passenger count \n",
    "if \"passenger_count\" in df.columns:\n",
    "    df = df.filter(\n",
    "        when(col(\"service_type\") == \"yellow\", col(\"passenger_count\") > 0)\n",
    "        .otherwise(True)\n",
    "    )\n",
    "\n",
    "# Valid TLC zone IDs \n",
    "for c in [\"PULocationID\", \"DOLocationID\"]:\n",
    "    if c in df.columns:\n",
    "        df = df.filter((col(c) >= 1) & (col(c) <= 263))\n",
    "\n",
    "# Non-negative money fields \n",
    "money_ok = (\n",
    "    (coalesce(col(\"fare_amount\"), lit(0.0))  >= 0) &\n",
    "    (coalesce(col(\"extra\"),       lit(0.0))  >= 0) &\n",
    "    (coalesce(col(\"tip_amount\"),  lit(0.0))  >= 0) &\n",
    "    (coalesce(col(\"driver_pay\"),  lit(0.0))  >= 0) &\n",
    "    (coalesce(col(\"tips\"),        lit(0.0))  >= 0)\n",
    ")\n",
    "df = df.filter(money_ok)\n",
    "\n",
    "# Minimum initial fare for Yellow \n",
    "df = df.filter(\n",
    "    when(col(\"service_type\") == \"yellow\", coalesce(col(\"fare_amount\"), lit(0.0)) >= 1.50)\n",
    "    .otherwise(True)\n",
    ")\n",
    "\n",
    "\n",
    "# Pre-fuel profitability\n",
    "df = (df\n",
    "    .withColumn(\"active_hours\", (col(\"trip_time_s\") / 3600.0).cast(DoubleType()))\n",
    "    .withColumn(\"net_before_fuel\", (col(\"revenue\") - col(\"expenses_nonfuel\")).cast(DoubleType()))\n",
    "    .withColumn(\"net_per_hr_before_fuel\", (col(\"net_before_fuel\") / col(\"active_hours\")).cast(DoubleType()))\n",
    "    .withColumn(\"mph\", (col(\"distance_mi\") / (col(\"trip_time_s\")/3600.0)).cast(DoubleType()))\n",
    ")\n",
    "\n",
    "# Single-pass outlier trim using 99.9% quantile\n",
    "stacked = (\n",
    "    df.select(\"service_type\", F.lit(\"distance_mi\").alias(\"metric\"), col(\"distance_mi\").alias(\"value\"))\n",
    "      .unionByName(df.select(\"service_type\", F.lit(\"trip_time_s\").alias(\"metric\"), col(\"trip_time_s\").alias(\"value\")))\n",
    "      .unionByName(df.select(\"service_type\", F.lit(\"revenue\").alias(\"metric\"),     col(\"revenue\").alias(\"value\")))\n",
    ")\n",
    "bounds = (\n",
    "    stacked.groupBy(\"service_type\", \"metric\")\n",
    "           .agg(F.expr(\"percentile_approx(value, 0.999, 10000)\").alias(\"p999\"))\n",
    ")\n",
    "df = (\n",
    "    df.alias(\"t\")\n",
    "      .join(bounds.alias(\"b1\").filter(col(\"b1.metric\") == \"distance_mi\")\n",
    "                 .select(col(\"service_type\").alias(\"s1\"), col(\"p999\").alias(\"p_d\")),\n",
    "            on=[col(\"t.service_type\") == col(\"s1\")], how=\"left\")\n",
    "      .join(bounds.alias(\"b2\").filter(col(\"b2.metric\") == \"trip_time_s\")\n",
    "                 .select(col(\"service_type\").alias(\"s2\"), col(\"p999\").alias(\"p_t\")),\n",
    "            on=[col(\"t.service_type\") == col(\"s2\")], how=\"left\")\n",
    "      .join(bounds.alias(\"b3\").filter(col(\"b3.metric\") == \"revenue\")\n",
    "                 .select(col(\"service_type\").alias(\"s3\"), col(\"p999\").alias(\"p_r\")),\n",
    "            on=[col(\"t.service_type\") == col(\"s3\")], how=\"left\")\n",
    "      .filter( (col(\"distance_mi\") <= F.coalesce(col(\"p_d\"), lit(float(\"inf\")))) &\n",
    "               (col(\"trip_time_s\") <= F.coalesce(col(\"p_t\"), lit(float(\"inf\")))) &\n",
    "               (col(\"revenue\")     <= F.coalesce(col(\"p_r\"), lit(float(\"inf\")))) )\n",
    "      .drop(\"s1\",\"s2\",\"s3\",\"p_d\",\"p_t\",\"p_r\")\n",
    ")\n",
    "\n",
    "df = df.repartition(64, \"service_type\", \"month\")\n",
    "\n",
    "# Cap impossible speeds\n",
    "df = df.filter((col(\"mph\") >= 0) & (col(\"mph\") <= 120.0))\n",
    "\n",
    "\n",
    "# Fuel and energy costs\n",
    "fuel = fuel.select(\"month\", \"price_per_gallon\").dropna()\n",
    "electricity = electricity.select(\"month\", \"price_usd_per_kwh\").dropna()\n",
    "\n",
    "# Join fuel and electricity prices\n",
    "df = (df.join(broadcast(fuel), on=\"month\", how=\"left\")\n",
    "        .join(broadcast(electricity), on=\"month\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Energy assumptions according to EPA and AFDC \n",
    "MPG_FHV  = 27.0  \n",
    "MPG_TAXI = 16.0  \n",
    "\n",
    "KWH_YELLOW = 0.30\n",
    "KWH_FHV    = 0.30\n",
    "\n",
    "YELLOW_EV_PERCENT = 0.00  # Assuming no EVs in Yellow Taxi fleet \n",
    "FHV_EV_PERCENT    = 0.10  # Example share for HVFHV\n",
    "\n",
    "# Per-service parameters as columns \n",
    "df = (df\n",
    "    .withColumn(\n",
    "        \"mpg\",\n",
    "        when(col(\"service_type\") == \"yellow\", lit(MPG_TAXI))\n",
    "        .otherwise(lit(MPG_FHV)).cast(DoubleType())\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"kwh_per_mile\",\n",
    "        when(col(\"service_type\") == \"yellow\", lit(KWH_YELLOW))\n",
    "        .otherwise(lit(KWH_FHV)).cast(DoubleType())\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"ev_share\",\n",
    "        when(col(\"service_type\") == \"yellow\", lit(YELLOW_EV_PERCENT))\n",
    "        .otherwise(lit(FHV_EV_PERCENT)).cast(DoubleType())\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cost per mile (blend gas vs EV by ev_share)\n",
    "gas_cpm = (col(\"price_per_gallon\") / col(\"mpg\")).cast(DoubleType())\n",
    "ev_cpm  = (col(\"price_usd_per_kwh\") * col(\"kwh_per_mile\")).cast(DoubleType())\n",
    "\n",
    "df = (df\n",
    "    .withColumn(\n",
    "        \"energy_cost_per_mile\",\n",
    "        ((lit(1.0) - coalesce(col(\"ev_share\"), lit(0.0))) * coalesce(gas_cpm, lit(0.0))) +\n",
    "        (coalesce(col(\"ev_share\"), lit(0.0)) * coalesce(ev_cpm, lit(0.0)))\n",
    "    )\n",
    "    .withColumn(\"expense_fuel\", (col(\"distance_mi\") * col(\"energy_cost_per_mile\")).cast(DoubleType()))\n",
    "    .withColumn(\"net_after_fuel\", (col(\"revenue\") - col(\"expenses_nonfuel\") - col(\"expense_fuel\")).cast(DoubleType()))\n",
    "    .withColumn(\"net_per_hr_after_fuel\", (col(\"net_after_fuel\") / col(\"active_hours\")).cast(DoubleType()))\n",
    ")\n",
    "\n",
    "# Keep only relevant columns\n",
    "cols_keep = [\n",
    "    # Metadata\n",
    "    \"service_type\", \"month\", \"pickup_ts\", \"dropoff_ts\",\n",
    "    \"pickup_hour\", \"pickup_dow\", \"is_weekend\",\n",
    "    # Location IDs\n",
    "    \"PULocationID\", \"DOLocationID\",\n",
    "    # engineered trip metrics\n",
    "    \"distance_mi\", \"trip_time_s\", \"mph\", \"active_hours\",\n",
    "    # Feature engineering\n",
    "    \"revenue\", \"expenses_nonfuel\", \"expense_fuel\",\n",
    "    \"net_before_fuel\", \"net_after_fuel\",\n",
    "    \"net_per_hr_before_fuel\", \"net_per_hr_after_fuel\",\n",
    "    # Parameters\n",
    "    \"price_per_gallon\", \"price_usd_per_kwh\",\n",
    "    \"energy_cost_per_mile\", \"ev_share\", \"mpg\", \"kwh_per_mile\",\n",
    "]\n",
    "\n",
    "# Filter columns to keep only those that exist in the DataFrame\n",
    "cols_keep = [c for c in cols_keep if c in df.columns]\n",
    "df = df.select(*cols_keep)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17467e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze results \n",
    "from pyspark.sql.functions import col, sum as ssum, count, round as sround, when, lit\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark import StorageLevel\n",
    "\n",
    "# Testing\n",
    "FAST_MODE = False  \n",
    "if FAST_MODE:\n",
    "    df_base = df.stat.sampleBy(\"service_type\", {\"yellow\": 0.02, \"hv_fhv\": 0.02}, seed=7)\n",
    "else:\n",
    "    df_base = df\n",
    "\n",
    "df_base = df.repartition(320, \"service_type\", \"month\")\n",
    "\n",
    "# Aggregate functions\n",
    "sum_net   = ssum(\"net_after_fuel\").alias(\"sum_net\")\n",
    "sum_hours = ssum(\"active_hours\").alias(\"sum_hours\")\n",
    "\n",
    "def safe_net_per_hr(df_agg):\n",
    "    return df_agg.withColumn(\n",
    "        \"net_per_hr_TW\",\n",
    "        sround(F.when(col(\"sum_hours\") > 0, col(\"sum_net\")/col(\"sum_hours\")), 2)\n",
    "    )\n",
    "\n",
    "# Overall net per hour\n",
    "overall = (\n",
    "    df_base.groupBy(\"service_type\")\n",
    "           .agg(sum_net, sum_hours, count(\"*\").alias(\"trips\"))\n",
    ")\n",
    "overall = safe_net_per_hr(overall)\n",
    "\n",
    "\n",
    "# Hour of day\n",
    "hod = (\n",
    "    df_base.groupBy(\"service_type\", \"pickup_hour\")\n",
    "           .agg(sum_net, sum_hours, count(\"*\").alias(\"trips\"))\n",
    ")\n",
    "hod = safe_net_per_hr(hod).orderBy(\"service_type\", \"pickup_hour\")\n",
    "\n",
    "\n",
    "# Earnings per trip\n",
    "comp = (\n",
    "    df_base.groupBy(\"service_type\")\n",
    "           .agg(\n",
    "               ssum(\"revenue\").alias(\"sum_rev\"),\n",
    "               ssum(\"expenses_nonfuel\").alias(\"sum_nonfuel\"),\n",
    "               ssum(\"expense_fuel\").alias(\"sum_fuel\"),\n",
    "               count(\"*\").alias(\"n_trips\")\n",
    "           )\n",
    "           .withColumn(\"rev_per_trip\",     sround(col(\"sum_rev\")/col(\"n_trips\"), 2))\n",
    "           .withColumn(\"nonfuel_per_trip\", sround(col(\"sum_nonfuel\")/col(\"n_trips\"), 2))\n",
    "           .withColumn(\"fuel_per_trip\",    sround(col(\"sum_fuel\")/col(\"n_trips\"), 2))\n",
    "           .select(\"service_type\",\"n_trips\",\"rev_per_trip\",\"nonfuel_per_trip\",\"fuel_per_trip\")\n",
    ")\n",
    "\n",
    "\n",
    "# Pickup density map\n",
    "zone_trips = (\n",
    "    df_base.groupBy(\"service_type\",\"PULocationID\")\n",
    "           .agg(count(\"*\").alias(\"trips\"))\n",
    "           .orderBy(\"service_type\", col(\"trips\").desc())\n",
    ")\n",
    "\n",
    "zone_pivot = (\n",
    "    df_base.groupBy(\"PULocationID\",\"service_type\").count()\n",
    "           .groupBy(\"PULocationID\")\n",
    "           .pivot(\"service_type\", [\"yellow\",\"hv_fhv\"])\n",
    "           .agg(F.first(\"count\"))\n",
    "           .fillna(0)\n",
    "           .withColumn(\"diff_pickups\", (col(\"yellow\") - col(\"hv_fhv\")).cast(\"int\"))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e07644c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "OVERALL (time-weighted net/hr):\n",
      "  service_type       sum_net     sum_hours      trips  net_per_hr_TW\n",
      "0       hv_fhv  2.084298e+09  3.643137e+07  115657673          57.21\n",
      "1       yellow  3.807349e+08  4.614320e+06   17193558          82.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Plotting results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import LineString\n",
    "import os\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "os.makedirs(\"plots/img\", exist_ok=True)\n",
    "\n",
    "# Overall Table\n",
    "overall_pd = overall.toPandas()\n",
    "print(\"\\nOVERALL (time-weighted net/hr):\")\n",
    "print(overall_pd)\n",
    "\n",
    "# Hour-of-day Plot\n",
    "hod_pd = hod.toPandas()\n",
    "hod_p = (\n",
    "    hod_pd.pivot(index=\"pickup_hour\", columns=\"service_type\", values=\"net_per_hr_TW\")\n",
    "          .reindex(range(24))  \n",
    "          .sort_index()\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,4)) \n",
    "hod_p.plot(ax=ax, marker=\"o\", linewidth=1.8, title=\"Time-weighted Net Profit by Hour of Day\")\n",
    "\n",
    "ax.set_xlabel(\"Pickup time\")\n",
    "ax.set_ylabel(\"Net $ per active hour\")\n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda v, _: f\"${v:,.0f}\"))\n",
    "\n",
    "major_xticks = list(range(0, 24, 2))\n",
    "ax.set_xticks(major_xticks)\n",
    "ax.set_xticklabels([f\"{h:02d}:00\" for h in major_xticks], rotation=0)\n",
    "\n",
    "ax.set_xticks(range(24), minor=True)                  \n",
    "ax.grid(True, axis=\"y\", alpha=0.3)                    \n",
    "ax.grid(True, which=\"minor\", axis=\"x\", alpha=0.12)    \n",
    "\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.axhline(0, linewidth=1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/img/hour_of_day.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# Composition\n",
    "comp_pd = comp.toPandas().set_index(\"service_type\")[[\"rev_per_trip\",\"nonfuel_per_trip\",\"fuel_per_trip\"]]\n",
    "\n",
    "ax = comp_pd.plot(kind=\"bar\", stacked=True, title=\"Per-trip Revenue vs Costs\")\n",
    "ax.set_xlabel(\"Service type\")              \n",
    "ax.set_ylabel(\"USD per trip\")              \n",
    "ax.yaxis.set_major_formatter(FuncFormatter(lambda v, _: f\"${v:,.0f}\")) \n",
    "\n",
    "ax.set_ylim(bottom=0)      \n",
    "ax.axhline(0, linewidth=1) \n",
    "ax.grid(True, axis=\"y\", alpha=0.3)\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/img/composition.png\", dpi=150)\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74e12dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# GEOSPATIAL\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# Load NYC Taxi Zones shapefile\n",
    "TAXI_ZONES_PATH = \"data/taxi_zones/taxi_zones.shp\"\n",
    "zones = gpd.read_file(TAXI_ZONES_PATH)[[\"LocationID\",\"geometry\",\"zone\",\"borough\"]]\n",
    "zones[\"LocationID\"] = pd.to_numeric(zones[\"LocationID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Difference between yellow and hv_fhv pickups\n",
    "zone_diff_pd = zone_pivot.toPandas().rename(\n",
    "    columns={\"PULocationID\": \"LocationID\", \"diff_pickups\": \"pickup_diff\"}\n",
    ")\n",
    "zone_diff_pd[\"LocationID\"] = pd.to_numeric(zone_diff_pd[\"LocationID\"], errors=\"coerce\").astype(\"Int64\")\n",
    "zone_diff_pd[\"pickup_diff\"] = pd.to_numeric(zone_diff_pd[\"pickup_diff\"], errors=\"coerce\")\n",
    "\n",
    "z_diff = zones.merge(zone_diff_pd[[\"LocationID\",\"pickup_diff\"]], on=\"LocationID\", how=\"left\")\n",
    "\n",
    "vals = z_diff[\"pickup_diff\"].astype(float).to_numpy()\n",
    "vmax = float(pd.Series(vals).abs().max()) if len(vals) else 1.0\n",
    "norm = TwoSlopeNorm(vmin=-vmax, vcenter=0, vmax=vmax)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "z_diff.plot(\n",
    "    column=\"pickup_diff\",\n",
    "    cmap=\"RdBu_r\",\n",
    "    legend=True,\n",
    "    norm=norm,\n",
    "    linewidth=0.2,\n",
    "    edgecolor=\"black\",\n",
    "    missing_kwds={\"color\": \"lightgrey\"},\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(\"Pickup Difference (Yellow âˆ’ HVFHV)\")\n",
    "ax.set_axis_off()  \n",
    "\n",
    "cax = fig.axes[-1]\n",
    "cax.set_ylabel(\"Pickups (difference)\")\n",
    "cax.yaxis.set_major_formatter(mtick.StrMethodFormatter(\"{x:,.0f}\"))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plots/img/map_pickups_diff.png\", dpi=150)\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast30034-venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
