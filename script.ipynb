{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f02a0c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Starts a Spark session\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "        .appName(\"Taxi vs Rideshare Profitability\")\n",
    "        .config(\"spark.sql.repl.eagerEval.enabled\", False)   \n",
    "        .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "        .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "        .config(\"spark.sql.shuffle.partitions\", \"64\")        \n",
    "        .config(\"spark.driver.memory\", \"6g\")                \n",
    "        .config(\"spark.executor.memory\", \"6g\")\n",
    "        .getOrCreate()\n",
    ")\n",
    "\n",
    "# Define months\n",
    "months = [\"2024-01\",\"2024-02\",\"2024-03\",\"2024-04\",\"2024-05\",\"2024-06\"]\n",
    "\n",
    "# Load in data files \n",
    "yellow_files = [f\"data/yellow/yellow_tripdata_{m}.parquet\" for m in months]\n",
    "fhvhv_files  = [f\"data/fhvhv/fhvhv_tripdata_{m}.parquet\"   for m in months]\n",
    "\n",
    "df_yellow = (\n",
    "    spark.read.parquet(*yellow_files)\n",
    "         .withColumn(\"service_type\", lit(\"yellow\"))\n",
    ")\n",
    "df_fhvhv = (\n",
    "    spark.read.parquet(*fhvhv_files)\n",
    "         .withColumn(\"service_type\", lit(\"hv_fhv\"))\n",
    ")\n",
    "\n",
    "# Merge\n",
    "df = df_yellow.unionByName(df_fhvhv, allowMissingColumns=True)\n",
    "\n",
    "# External tables (you'll wire these in later for fuel/energy)\n",
    "electricity = spark.read.csv(\"data/external/electricity.csv\", header=True, inferSchema=True)\n",
    "fuel        = spark.read.csv(\"data/external/fuel.csv\", header=True, inferSchema=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c04cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing required cols: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 338:>              (0 + 16) / 40][Stage 339:>               (0 + 0) / 40]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+---------+----------+-----------+-----------+------------+-------+----------------+------------+--------------+---------------------+\n",
      "|service_type|month|pickup_ts|dropoff_ts|distance_mi|trip_time_s|active_hours|revenue|expenses_nonfuel|expense_fuel|net_after_fuel|net_per_hr_after_fuel|\n",
      "+------------+-----+---------+----------+-----------+-----------+------------+-------+----------------+------------+--------------+---------------------+\n",
      "|0           |0    |0        |0         |0          |0          |0           |0      |0               |0           |0             |0                    |\n",
      "+------------+-----+---------+----------+-----------+-----------+------------+-------+----------------+------------+--------------+---------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+----------------+-----------+-----------+--------+\n",
      "|bad_distance|bad_time|bad_active_hours|neg_revenue|neg_nonfuel|neg_fuel|\n",
      "+------------+--------+----------------+-----------+-----------+--------+\n",
      "|           0|       0|               0|          0|          0|       0|\n",
      "+------------+--------+----------------+-----------+-----------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+------+\n",
      "|service_type|month  |count |\n",
      "+------------+-------+------+\n",
      "|hv_fhv      |2024-01|378223|\n",
      "|hv_fhv      |2024-02|371013|\n",
      "|hv_fhv      |2024-03|408127|\n",
      "|hv_fhv      |2024-04|377274|\n",
      "|hv_fhv      |2024-05|395728|\n",
      "|hv_fhv      |2024-06|383663|\n",
      "|yellow      |2024-01|52841 |\n",
      "|yellow      |2024-02|52782 |\n",
      "|yellow      |2024-03|59524 |\n",
      "|yellow      |2024-04|58244 |\n",
      "|yellow      |2024-05|61970 |\n",
      "|yellow      |2024-06|58353 |\n",
      "+------------+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yellow mph q01/median/q99: [0.061381074168797956, 9.310344827586206, 559.813953488372]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hv_fhv mph q01/median/q99: [0.16445865692096848, 11.172413793103448, 78.23904382470118]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------------+-----------------+------------------------+\n",
      "|service_type|sum_net            |sum_hours        |net_per_hr_time_weighted|\n",
      "+------------+-------------------+-----------------+------------------------+\n",
      "|yellow      |7600614.158874975  |92077.94500000012|82.55                   |\n",
      "|hv_fhv      |4.165337675916819E7|728400.3625000088|57.18                   |\n",
      "+------------+-------------------+-----------------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess data\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, to_timestamp, coalesce, unix_timestamp, when, lit, date_format, hour, dayofweek, broadcast\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "from pyspark import StorageLevel\n",
    "from pyspark.sql import Window\n",
    "\n",
    "# Reduce memory usage\n",
    "_needed = [\n",
    "    \"service_type\",\n",
    "    \"tpep_pickup_datetime\",\"tpep_dropoff_datetime\",\n",
    "    \"pickup_datetime\",\"dropoff_datetime\",\n",
    "    \"trip_distance\",\"trip_miles\",\"trip_time\",\n",
    "    \"PULocationID\",\"DOLocationID\",\n",
    "    \"passenger_count\",\"payment_type\",\n",
    "    \"fare_amount\",\"extra\",\"tip_amount\",\n",
    "    \"driver_pay\",\"tips\"\n",
    "]\n",
    "df = df.select([c for c in _needed if c in df.columns])\n",
    "\n",
    "# Standardise timestamps\n",
    "df = (\n",
    "    df.withColumn(\"pickup_ts\",  to_timestamp(coalesce(col(\"tpep_pickup_datetime\"),  col(\"pickup_datetime\"))))\n",
    "      .withColumn(\"dropoff_ts\", to_timestamp(coalesce(col(\"tpep_dropoff_datetime\"), col(\"dropoff_datetime\"))))\n",
    ")\n",
    "\n",
    "# Remove rows with null pickup or dropoff timestamps\n",
    "df = df.filter(col(\"pickup_ts\").isNotNull() & col(\"dropoff_ts\").isNotNull())\n",
    "\n",
    "# Standardise location IDs\n",
    "df = df.withColumn(\"month\", date_format(col(\"pickup_ts\"), \"yyyy-MM\"))\n",
    "\n",
    "# Standardise distance and keep positive distances only and not null\n",
    "df = (\n",
    "    df.withColumn(\"distance_mi\", coalesce(col(\"trip_distance\"), col(\"trip_miles\")).cast(DoubleType()))\n",
    "      .filter(col(\"distance_mi\").isNotNull() & (col(\"distance_mi\") > 0))\n",
    ")\n",
    "\n",
    "# Standardise trip time and not null\n",
    "df = df.withColumn(\n",
    "    \"trip_time_s\",\n",
    "    when(col(\"trip_time\").isNotNull(), col(\"trip_time\").cast(\"double\"))\n",
    "    .otherwise((unix_timestamp(col(\"dropoff_ts\")) - unix_timestamp(col(\"pickup_ts\"))).cast(\"double\"))\n",
    ")\n",
    "df = df.filter(col(\"trip_time_s\").isNotNull() & (col(\"trip_time_s\") > 0))\n",
    "\n",
    "# Deduplicate rows \n",
    "dedupe_key = [c for c in [\"service_type\",\"pickup_ts\",\"dropoff_ts\",\"PULocationID\",\"DOLocationID\",\"distance_mi\",\"trip_time_s\"] if c in df.columns]\n",
    "\n",
    "# If dedupe_key is empty, we won't deduplicate\n",
    "if dedupe_key:\n",
    "    w = Window.partitionBy([\"month\"] + dedupe_key).orderBy(F.lit(1))\n",
    "    df = df.withColumn(\"__rn\", F.row_number().over(w)).filter(col(\"__rn\") == 1).drop(\"__rn\")\n",
    "\n",
    "# Fixed Parameters\n",
    "CREDIT_CARD_FEE = 0.025 \n",
    "MAINTENANCE_COST_PER_MILE = 0.15\n",
    "MAINTENANCE_COST_PER_MILE_HV = 0.15\n",
    "\n",
    "# Payment type exists\n",
    "if \"payment_type\" not in df.columns:\n",
    "    df = df.withColumn(\"payment_type\", lit(None).cast(IntegerType()))\n",
    "\n",
    "# Time features \n",
    "df = (df\n",
    "    .withColumn(\"pickup_hour\", hour(col(\"pickup_ts\")))\n",
    "    .withColumn(\"pickup_dow\", dayofweek(col(\"pickup_ts\")))  \n",
    "    .withColumn(\"is_weekend\", (col(\"pickup_dow\").isin([1,7])).cast(\"boolean\"))\n",
    ")\n",
    "\n",
    "# Add revenue \n",
    "rev_yellow = coalesce(col(\"fare_amount\"), lit(0.0)) + coalesce(col(\"extra\"), lit(0.0)) + coalesce(col(\"tip_amount\"), lit(0.0))\n",
    "rev_hv     = coalesce(col(\"driver_pay\"), lit(0.0)) + coalesce(col(\"tips\"), lit(0.0))\n",
    "df = df.withColumn(\n",
    "    \"revenue\",\n",
    "    when(col(\"service_type\") == \"yellow\", rev_yellow).otherwise(rev_hv).cast(DoubleType())\n",
    ")\n",
    "\n",
    "# Add costs\n",
    "maint_rate = when(col(\"service_type\") == \"yellow\",\n",
    "                  lit(MAINTENANCE_COST_PER_MILE)\n",
    "              ).otherwise(\n",
    "                  lit(MAINTENANCE_COST_PER_MILE_HV)\n",
    "              )\n",
    "df = df.withColumn(\"expense_maintenance\", (col(\"distance_mi\") * maint_rate).cast(DoubleType()))\n",
    "\n",
    "# Credit card fee \n",
    "df = df.withColumn(\n",
    "     \"expense_cc_processing\",\n",
    "    when((col(\"service_type\") == \"yellow\") & (col(\"payment_type\") == 1),\n",
    "         (lit(CREDIT_CARD_FEE) * col(\"revenue\")).cast(DoubleType()))\n",
    "    .otherwise(lit(0.0))\n",
    ")\n",
    "\n",
    "# Expenses pre-fuel \n",
    "df = df.withColumn(\n",
    "    \"expenses_nonfuel\",\n",
    "    (col(\"expense_maintenance\") + col(\"expense_cc_processing\")).cast(DoubleType())\n",
    ")\n",
    "\n",
    "# Keep distance\n",
    "df = df.filter(col(\"distance_mi\") >= 0.1)\n",
    "\n",
    "# Make sure within month range\n",
    "df = df.filter( (col(\"month\") >= \"2024-01\") & (col(\"month\") <= \"2024-06\") )\n",
    "\n",
    "# Keep duration >= 60 seconds\n",
    "df = df.filter(col(\"trip_time_s\") >= 60)\n",
    "\n",
    "# Keep positive passenger count \n",
    "if \"passenger_count\" in df.columns:\n",
    "    df = df.filter(\n",
    "        when(col(\"service_type\") == \"yellow\", col(\"passenger_count\") > 0)\n",
    "        .otherwise(True)\n",
    "    )\n",
    "\n",
    "# Valid TLC zone IDs \n",
    "for c in [\"PULocationID\", \"DOLocationID\"]:\n",
    "    if c in df.columns:\n",
    "        df = df.filter((col(c) >= 1) & (col(c) <= 263))\n",
    "\n",
    "# Non-negative money fields \n",
    "money_ok = (\n",
    "    (coalesce(col(\"fare_amount\"), lit(0.0))  >= 0) &\n",
    "    (coalesce(col(\"extra\"),       lit(0.0))  >= 0) &\n",
    "    (coalesce(col(\"tip_amount\"),  lit(0.0))  >= 0) &\n",
    "    (coalesce(col(\"driver_pay\"),  lit(0.0))  >= 0) &\n",
    "    (coalesce(col(\"tips\"),        lit(0.0))  >= 0)\n",
    ")\n",
    "df = df.filter(money_ok)\n",
    "\n",
    "# Minimum initial fare for Yellow \n",
    "df = df.filter(\n",
    "    when(col(\"service_type\") == \"yellow\", coalesce(col(\"fare_amount\"), lit(0.0)) >= 1.50)\n",
    "    .otherwise(True)\n",
    ")\n",
    "\n",
    "# Pre-fuel profitability\n",
    "df = (df\n",
    "    .withColumn(\"active_hours\", (col(\"trip_time_s\") / 3600.0).cast(DoubleType()))\n",
    "    .withColumn(\"net_before_fuel\", (col(\"revenue\") - col(\"expenses_nonfuel\")).cast(DoubleType()))\n",
    "    .withColumn(\"net_per_hr_before_fuel\", (col(\"net_before_fuel\") / col(\"active_hours\")).cast(DoubleType()))\n",
    "    .withColumn(\"mph\", (col(\"distance_mi\") / (col(\"trip_time_s\")/3600.0)).cast(DoubleType()))\n",
    ")\n",
    "\n",
    "# Single-pass outlier trim using 99.9% quantile\n",
    "stacked = (\n",
    "    df.select(\"service_type\", F.lit(\"distance_mi\").alias(\"metric\"), col(\"distance_mi\").alias(\"value\"))\n",
    "      .unionByName(df.select(\"service_type\", F.lit(\"trip_time_s\").alias(\"metric\"), col(\"trip_time_s\").alias(\"value\")))\n",
    "      .unionByName(df.select(\"service_type\", F.lit(\"revenue\").alias(\"metric\"),     col(\"revenue\").alias(\"value\")))\n",
    ")\n",
    "bounds = (\n",
    "    stacked.groupBy(\"service_type\", \"metric\")\n",
    "           .agg(F.expr(\"percentile_approx(value, 0.999, 10000)\").alias(\"p999\"))\n",
    ")\n",
    "df = (\n",
    "    df.alias(\"t\")\n",
    "      .join(bounds.alias(\"b1\").filter(col(\"b1.metric\") == \"distance_mi\")\n",
    "                 .select(col(\"service_type\").alias(\"s1\"), col(\"p999\").alias(\"p_d\")),\n",
    "            on=[col(\"t.service_type\") == col(\"s1\")], how=\"left\")\n",
    "      .join(bounds.alias(\"b2\").filter(col(\"b2.metric\") == \"trip_time_s\")\n",
    "                 .select(col(\"service_type\").alias(\"s2\"), col(\"p999\").alias(\"p_t\")),\n",
    "            on=[col(\"t.service_type\") == col(\"s2\")], how=\"left\")\n",
    "      .join(bounds.alias(\"b3\").filter(col(\"b3.metric\") == \"revenue\")\n",
    "                 .select(col(\"service_type\").alias(\"s3\"), col(\"p999\").alias(\"p_r\")),\n",
    "            on=[col(\"t.service_type\") == col(\"s3\")], how=\"left\")\n",
    "      .filter( (col(\"distance_mi\") <= F.coalesce(col(\"p_d\"), lit(float(\"inf\")))) &\n",
    "               (col(\"trip_time_s\") <= F.coalesce(col(\"p_t\"), lit(float(\"inf\")))) &\n",
    "               (col(\"revenue\")     <= F.coalesce(col(\"p_r\"), lit(float(\"inf\")))) )\n",
    "      .drop(\"s1\",\"s2\",\"s3\",\"p_d\",\"p_t\",\"p_r\")\n",
    ")\n",
    "\n",
    "df = df.repartition(64, \"service_type\", \"month\")\n",
    "\n",
    "# Fuel and energy costs\n",
    "fuel = fuel.select(\"month\", \"price_per_gallon\").dropna()\n",
    "electricity = electricity.select(\"month\", \"price_usd_per_kwh\").dropna()\n",
    "\n",
    "# Join fuel and electricity prices\n",
    "df = (df.join(broadcast(fuel), on=\"month\", how=\"left\")\n",
    "        .join(broadcast(electricity), on=\"month\", how=\"left\")\n",
    ")\n",
    "\n",
    "# Energy assumptions according to EPA and AFDC \n",
    "MPG_FHV  = 27.0  \n",
    "MPG_TAXI = 16.0  \n",
    "\n",
    "KWH_YELLOW = 0.30\n",
    "KWH_FHV    = 0.30\n",
    "\n",
    "YELLOW_EV_PERCENT = 0.00  # Assuming no EVs in Yellow Taxi fleet \n",
    "FHV_EV_PERCENT    = 0.10  # Example share for HVFHV\n",
    "\n",
    "# Per-service parameters as columns \n",
    "df = (df\n",
    "    .withColumn(\n",
    "        \"mpg\",\n",
    "        when(col(\"service_type\") == \"yellow\", lit(MPG_TAXI))\n",
    "        .otherwise(lit(MPG_FHV)).cast(DoubleType())\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"kwh_per_mile\",\n",
    "        when(col(\"service_type\") == \"yellow\", lit(KWH_YELLOW))\n",
    "        .otherwise(lit(KWH_FHV)).cast(DoubleType())\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"ev_share\",\n",
    "        when(col(\"service_type\") == \"yellow\", lit(YELLOW_EV_PERCENT))\n",
    "        .otherwise(lit(FHV_EV_PERCENT)).cast(DoubleType())\n",
    "    )\n",
    ")\n",
    "\n",
    "# Cost per mile (blend gas vs EV by ev_share)\n",
    "gas_cpm = (col(\"price_per_gallon\") / col(\"mpg\")).cast(DoubleType())\n",
    "ev_cpm  = (col(\"price_usd_per_kwh\") * col(\"kwh_per_mile\")).cast(DoubleType())\n",
    "\n",
    "df = (df\n",
    "    .withColumn(\n",
    "        \"energy_cost_per_mile\",\n",
    "        ((lit(1.0) - coalesce(col(\"ev_share\"), lit(0.0))) * coalesce(gas_cpm, lit(0.0))) +\n",
    "        (coalesce(col(\"ev_share\"), lit(0.0)) * coalesce(ev_cpm, lit(0.0)))\n",
    "    )\n",
    "    .withColumn(\"expense_fuel\", (col(\"distance_mi\") * col(\"energy_cost_per_mile\")).cast(DoubleType()))\n",
    "    .withColumn(\"net_after_fuel\", (col(\"revenue\") - col(\"expenses_nonfuel\") - col(\"expense_fuel\")).cast(DoubleType()))\n",
    "    .withColumn(\"net_per_hr_after_fuel\", (col(\"net_after_fuel\") / col(\"active_hours\")).cast(DoubleType()))\n",
    ")\n",
    "\n",
    "# Keep only relevant columns\n",
    "cols_keep = [\n",
    "    # Metadata\n",
    "    \"service_type\", \"month\", \"pickup_ts\", \"dropoff_ts\",\n",
    "    \"pickup_hour\", \"pickup_dow\", \"is_weekend\",\n",
    "    # Location IDs\n",
    "    \"PULocationID\", \"DOLocationID\",\n",
    "    # engineered trip metrics\n",
    "    \"distance_mi\", \"trip_time_s\", \"mph\", \"active_hours\",\n",
    "    # Feature engineering\n",
    "    \"revenue\", \"expenses_nonfuel\", \"expense_fuel\",\n",
    "    \"net_before_fuel\", \"net_after_fuel\",\n",
    "    \"net_per_hr_before_fuel\", \"net_per_hr_after_fuel\",\n",
    "    # Parameters\n",
    "    \"price_per_gal\", \"price_usd_per_kwh\",\n",
    "    \"energy_cost_per_mile\", \"ev_share\", \"mpg\", \"kwh_per_mile\",\n",
    "]\n",
    "\n",
    "# Filter columns to keep only those that exist in the DataFrame\n",
    "cols_keep = [c for c in cols_keep if c in df.columns]\n",
    "df = df.select(*cols_keep)\n",
    "\n",
    "\n",
    "# --- Sanity checks (append at end) ---\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, when, sum as ssum, round as sround\n",
    "\n",
    "# (optional speed-up for dev runs)\n",
    "FAST_MODE = True\n",
    "df_checks = df.sample(False, 0.02, seed=7) if FAST_MODE else df\n",
    "\n",
    "# 1) Required columns present & non-null\n",
    "required = [\n",
    "    \"service_type\",\"month\",\"pickup_ts\",\"dropoff_ts\",\n",
    "    \"distance_mi\",\"trip_time_s\",\"active_hours\",\n",
    "    \"revenue\",\"expenses_nonfuel\",\"expense_fuel\",\n",
    "    \"net_after_fuel\",\"net_per_hr_after_fuel\"\n",
    "]\n",
    "missing = [c for c in required if c not in df.columns]\n",
    "print(\"Missing required cols:\", missing)\n",
    "\n",
    "nulls = df_checks.agg(*[\n",
    "    ssum(when(col(c).isNull(), 1).otherwise(0)).alias(c)\n",
    "    for c in required if c in df.columns\n",
    "])\n",
    "nulls.show(truncate=False)\n",
    "\n",
    "# 2) Basic range checks\n",
    "df_checks.select(\n",
    "    ssum(when(col(\"distance_mi\") <= 0, 1).otherwise(0)).alias(\"bad_distance\"),\n",
    "    ssum(when(col(\"trip_time_s\") <= 0, 1).otherwise(0)).alias(\"bad_time\"),\n",
    "    ssum(when(col(\"active_hours\") <= 0, 1).otherwise(0)).alias(\"bad_active_hours\"),\n",
    "    ssum(when(col(\"revenue\") < 0, 1).otherwise(0)).alias(\"neg_revenue\"),\n",
    "    ssum(when(col(\"expenses_nonfuel\") < 0, 1).otherwise(0)).alias(\"neg_nonfuel\"),\n",
    "    ssum(when(col(\"expense_fuel\") < 0, 1).otherwise(0)).alias(\"neg_fuel\")\n",
    ").show()\n",
    "\n",
    "# 3) Month coverage\n",
    "df_checks.groupBy(\"service_type\",\"month\").count().orderBy(\"service_type\",\"month\").show(12, truncate=False)\n",
    "\n",
    "# 4) Speed sanity (quantiles)\n",
    "for svc in [\"yellow\",\"hv_fhv\"]:\n",
    "    q = df_checks.filter(col(\"service_type\")==svc).approxQuantile(\"mph\", [0.01, 0.5, 0.99], 0.01)\n",
    "    print(f\"{svc} mph q01/median/q99:\", q)\n",
    "\n",
    "# 5) Time-weighted hourly (headline)\n",
    "tw = (df_checks.groupBy(\"service_type\")\n",
    "        .agg(\n",
    "            ssum(\"net_after_fuel\").alias(\"sum_net\"),\n",
    "            ssum(\"active_hours\").alias(\"sum_hours\")\n",
    "        )\n",
    "        .withColumn(\"net_per_hr_time_weighted\", sround(col(\"sum_net\")/col(\"sum_hours\"), 2)))\n",
    "tw.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17467e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mast30034-venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
